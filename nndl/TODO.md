éå¸¸æ¸…æ™°ï¼ä½ çš„å®éªŒç›®æ ‡æ˜¯é€šè¿‡ **CIFAR-10 æ•°æ®é›†** æ¯”è¾ƒ **Adam** å’Œ **SGD** åœ¨ **MSE** ä¸ **CE** æŸå¤±å‡½æ•°ä¸‹çš„ **æ³›åŒ–èƒ½åŠ›**ï¼ŒåŒæ—¶éœ€è¦è¯¦ç»†è®°å½•æ¯ä¸ªè®­ç»ƒ epoch çš„ **loss**ï¼Œå¹¶ä¿å­˜æ‰€æœ‰çš„ **checkpoint**ã€‚ä¸ºäº†å¸®åŠ© **Codex** é«˜æ•ˆç”Ÿæˆä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥æ˜ç¡®æ¯ä¸ªæ­¥éª¤å¹¶ä¸”è®¾ç½®å¥½æ¡†æ¶ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªè¯¦ç»†çš„ **TODO.md** æ–‡ä»¶ï¼Œå®ƒå°†ä¸ºä½ åœ¨ **Codex** ç”Ÿæˆä»£ç æ—¶æä¾›æ¸…æ™°çš„æŒ‡å¼•ã€‚

---

## âœ… **TODO.md - NNDL Project**

```markdown
# NNDL Project - Adam vs SGD æ³›åŒ–èƒ½åŠ›ç ”ç©¶

## ğŸ¯ ç ”ç©¶ç›®æ ‡
æœ¬é¡¹ç›®æ—¨åœ¨æ¢ç©¶ **Adam** å’Œ **SGD** åœ¨ä¸åŒæŸå¤±å‡½æ•°ï¼ˆ**MSE** å’Œ **CE**ï¼‰ä¸‹çš„æ³›åŒ–èƒ½åŠ›å·®å¼‚ã€‚ä½¿ç”¨ **CIFAR-10** æ•°æ®é›†ï¼Œå¹¶é…ç½®ä¸åŒçš„å­¦ä¹ ç‡ï¼ˆ`0.001`, `0.005`, `0.01`, `0.1`ï¼‰è¿›è¡Œè®­ç»ƒã€‚å®éªŒä¸­éœ€è¦è®°å½•æ¯ä¸ª epoch çš„è®­ç»ƒè¿‡ç¨‹ï¼Œå­˜å‚¨æ‰€æœ‰ä¸­é—´ **loss** å’Œ **checkpoint**ã€‚

## ğŸ§© é¡¹ç›®ç»“æ„
```

NNDL/
â”œâ”€â”€ config/            # ğŸ“¦ é…ç½®æ–‡ä»¶ï¼ˆè¶…å‚æ•°é…ç½®ï¼‰
â”‚   â”œâ”€â”€ default.yaml   # åŸºç¡€é…ç½®ï¼ˆå­¦ä¹ ç‡ã€epochsï¼‰
â”‚   â”œâ”€â”€ adam_config.yaml  # Adam é…ç½®
â”‚   â””â”€â”€ sgd_config.yaml  # SGD é…ç½®
â”‚
â”œâ”€â”€ datasets/          # ğŸ“‚ æ•°æ®é›†åŠ è½½ä¸å¤„ç†
â”‚   â””â”€â”€ cifar10.py     # CIFAR-10 æ•°æ®åŠ è½½è„šæœ¬
â”‚
â”œâ”€â”€ models/            # ğŸ§© æ¨¡å‹å®ç°
â”‚   â”œâ”€â”€ VGG.py         # VGG æ¨¡å‹
â”‚   â”œâ”€â”€ ResNet.py      # ResNet æ¨¡å‹
â”‚   â””â”€â”€ **init**.py    # æ¨¡å‹æ„å»ºå…¥å£
â”‚
â”œâ”€â”€ scripts/           # ğŸ§ª è®­ç»ƒä¸å®éªŒè„šæœ¬
â”‚   â”œâ”€â”€ train.py       # è®­ç»ƒè„šæœ¬ï¼ˆä¸»è„šæœ¬ï¼‰
â”‚   â”œâ”€â”€ plot_loss.py   # ç»˜åˆ¶è®­ç»ƒè¿‡ç¨‹ä¸­ loss æ›²çº¿
â”‚   â”œâ”€â”€ analyze.py     # åˆ†æä¸ç»“æœæ±‡æ€»è„šæœ¬
â”‚   â””â”€â”€ evaluate.py    # æµ‹è¯•ä¸è¯„ä¼°è„šæœ¬
â”‚
â”œâ”€â”€ output/            # ğŸ“Š ä¿å­˜æ—¥å¿—ã€æ¨¡å‹
â”‚   â”œâ”€â”€ checkpoints/   # æ¨¡å‹æ£€æŸ¥ç‚¹ä¿å­˜ç›®å½•
â”‚   â”œâ”€â”€ logs/          # è®­ç»ƒè¿‡ç¨‹æ—¥å¿—
â”‚   â””â”€â”€ figures/       # ç»˜åˆ¶çš„å›¾å½¢ï¼ˆlossæ›²çº¿ã€accï¼‰
â”‚
â”œâ”€â”€ README.md          # é¡¹ç›®ä»‹ç»ä¸è¿è¡Œè¯´æ˜
â””â”€â”€ train.py           # å…¥å£è„šæœ¬ï¼ˆç”¨äºå¯åŠ¨è®­ç»ƒï¼‰

````

---

## âœ… **1. é…ç½®æ–‡ä»¶ç®¡ç† (config)**

### 1.1 **`config/default.yaml`**
- é…ç½®æ‰€æœ‰åŸºç¡€çš„è¶…å‚æ•°ï¼ˆå¦‚ï¼š`epochs`, `batch_size`, `seed`, `device`ï¼‰

```yaml
# é»˜è®¤é…ç½®
seed: 42
epochs: 30
batch_size: 128
device: "cuda"  # "cpu" / "cuda"

learning_rates: [0.001, 0.005, 0.01, 0.1]  # å››ä¸ªå­¦ä¹ ç‡æ¡£ä½
````

### 1.2 **`config/adam_config.yaml`**

* é…ç½® Adam ä¼˜åŒ–å™¨çš„è¶…å‚æ•°ï¼ˆå¦‚ `lr`, `betas`, `weight_decay`ï¼‰

```yaml
optimizer: 
  type: "adam"
  lr: 0.001
  betas: [0.9, 0.999]
  weight_decay: 0.0
```

### 1.3 **`config/sgd_config.yaml`**

* é…ç½® SGD ä¼˜åŒ–å™¨çš„è¶…å‚æ•°ï¼ˆå¦‚ `lr`, `momentum`, `weight_decay`ï¼‰

```yaml
optimizer:
  type: "sgd"
  lr: 0.001
  momentum: 0.9
  weight_decay: 0.0
```

---

## âœ… **2. æ•°æ®é›†åŠ è½½ (datasets)**

### 2.1 **`datasets/cifar10.py`**

* è´Ÿè´£åŠ è½½ **CIFAR-10** æ•°æ®é›†å¹¶è¿›è¡Œé¢„å¤„ç†
* ä½¿ç”¨ `torchvision` æä¾›çš„æ ‡å‡†æ¥å£åŠ è½½æ•°æ®é›†å¹¶è¿›è¡Œæ ‡å‡†åŒ–ã€‚

```python
import torch
from torchvision import datasets, transforms

def get_dataloader(batch_size=128, train=True, seed=42):
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
    ])
    
    dataset = datasets.CIFAR10(root='./data', train=train, download=True, transform=transform)
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)
    
    return dataloader
```

---

## âœ… **3. æ¨¡å‹å®šä¹‰ (models)**

### 3.1 **`models/VGG.py`**

* å®šä¹‰ **VGG** ç½‘ç»œï¼Œå¹¶æ”¯æŒ CIFAR-10 ç‰ˆè¾“å‡ºå±‚ã€‚

```python
import torch.nn as nn
import torchvision.models as models

def VGG11():
    model = models.vgg11_bn(weights=None)
    model.classifier[6] = nn.Linear(4096, 10)  # CIFAR-10 åˆ†ç±»
    return model
```

### 3.2 **`models/ResNet.py`**

* å®šä¹‰ **ResNet18** ç½‘ç»œï¼Œè°ƒæ•´è¾“å‡ºå±‚ä»¥é€‚åº” CIFAR-10ã€‚

```python
import torch.nn as nn
import torchvision.models as models

def ResNet18():
    model = models.resnet18(weights=None)
    model.fc = nn.Linear(model.fc.in_features, 10)  # CIFAR-10 åˆ†ç±»
    return model
```

### 3.3 **`models/__init__.py`**

* æä¾›ä¸€ä¸ªç»Ÿä¸€å…¥å£ï¼Œç”¨äºåŠ è½½ä¸åŒçš„æ¨¡å‹ã€‚

```python
from .VGG import VGG11
from .ResNet import ResNet18

def build_model(model_name="ResNet18"):
    if model_name == "VGG11":
        return VGG11()
    elif model_name == "ResNet18":
        return ResNet18()
    else:
        raise ValueError("Model not found!")
```

---

## âœ… **4. è®­ç»ƒè„šæœ¬ (scripts/train.py)**

### 4.1 **è®­ç»ƒæµç¨‹**

* åŠ è½½é…ç½®æ–‡ä»¶ï¼Œé€‰æ‹©æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°ã€‚
* å¯¹äºæ¯ä¸ªå­¦ä¹ ç‡æ¡£æ¬¡è¿è¡Œè®­ç»ƒè¿‡ç¨‹ï¼Œè®°å½•è®­ç»ƒæ—¥å¿—å’Œæ¨¡å‹ã€‚
* æ¯ä¸ª epoch ç»“æŸæ—¶ä¿å­˜ **checkpoint**ã€‚

```python
import torch
import torch.optim as optim
import torch.nn as nn
from models import build_model
from datasets.cifar10 import get_dataloader
import yaml
import os

# åŠ è½½é…ç½®
with open('config/adam_config.yaml', 'r') as f:
    config = yaml.load(f, Loader=yaml.FullLoader)

device = torch.device(config['device'])

# æ¨¡å‹ã€ä¼˜åŒ–å™¨
model = build_model("ResNet18").to(device)
optimizer = optim.Adam(model.parameters(), lr=config['optimizer']['lr'], betas=config['optimizer']['betas'])

# æ•°æ®åŠ è½½
train_loader = get_dataloader(batch_size=128)
test_loader = get_dataloader(batch_size=128, train=False)

# æŸå¤±å‡½æ•°
criterion = nn.CrossEntropyLoss()

# è®­ç»ƒå¾ªç¯
for epoch in range(1, config['epochs'] + 1):
    model.train()
    running_loss = 0.0
    for i, (inputs, targets) in enumerate(train_loader):
        inputs, targets = inputs.to(device), targets.to(device)

        optimizer.zero_grad()

        outputs = model(inputs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    print(f'Epoch {epoch}, Loss: {running_loss / len(train_loader)}')

    # ä¿å­˜æ¨¡å‹ checkpoint
    torch.save(model.state_dict(), f'output/checkpoints/model_epoch_{epoch}.pth')
```

---

## âœ… **5. å¯è§†åŒ– (scripts/plot_loss.py)**

### 5.1 **å®æ—¶ç»˜åˆ¶è®­ç»ƒæŸå¤±**

* ä½¿ç”¨ `matplotlib` è¿›è¡Œå®æ—¶æŸå¤±ç»˜åˆ¶ã€‚

```python
import matplotlib.pyplot as plt

def plot_loss(train_losses, test_losses):
    plt.ion()
    plt.figure(figsize=(10, 6))
    plt.plot(train_losses, label='Train Loss')
    plt.plot(test_losses, label='Test Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend(loc='upper right')
    plt.pause(0.1)
```

---

## âœ… **6. ç»“æœåˆ†æä¸è¯„ä¼° (scripts/analyze.py)**

### 6.1 **åˆ†æä¸åŒä¼˜åŒ–å™¨ä¸æŸå¤±ä¸‹çš„è¡¨ç°**

* ç»Ÿè®¡æ¯ä¸ªå­¦ä¹ ç‡æ¡£æ¬¡çš„ **test_acc**, **Hessian**, **sharpness**ï¼Œå¹¶ç»˜åˆ¶å¯¹æ¯”å›¾ã€‚

```python
import pandas as pd
import matplotlib.pyplot as plt

def analyze_results():
    df = pd.read_csv('output/logs/results.csv')
    df.groupby('learning_rate')['test_acc'].mean().plot()
    plt.xlabel('Learning Rate')
    plt.ylabel('Average Test Accuracy')
    plt.title('Adam vs SGD Generalization')
    plt.show()
```

---

## âœ… **7. Checkpoints & ç»“æœå­˜å‚¨**

* æ¯æ¬¡è®­ç»ƒåä¿å­˜ **checkpoint**ï¼š

  * è®­ç»ƒè¿‡ç¨‹çš„æ—¥å¿—ã€æ¯ä¸ª epoch çš„æ¨¡å‹ã€‚
  * å­˜å‚¨ `output/checkpoints` å’Œ `output/logs/`ã€‚

---

## âœ… **8. æœªæ¥æ‰©å±•**

* [ ] **å¼•å…¥å­¦ä¹ ç‡è°ƒåº¦å™¨**ï¼ˆå¦‚ `ReduceLROnPlateau`ï¼‰ã€‚
* [ ] **Hessian åˆ†æ**ï¼šå¯¹æ¯”ä¸åŒæ¨¡å‹ã€æŸå¤±ä¸‹çš„ **Hessian è°±**ã€‚
* [ ] **Sharpness Proxy**ï¼šé‡åŒ–æ¨¡å‹å¹³å¦åº¦ã€‚
* [ ] **å¤šä»»åŠ¡è®­ç»ƒ**ï¼šé€šè¿‡å¤šæ¨¡å‹ï¼ˆResNet / VGGï¼‰å’Œä¸åŒä»»åŠ¡çš„å¯¹æ¯”è¿›ä¸€æ­¥éªŒè¯ã€‚

---

## âœ… **9. è¿è¡ŒæŒ‡å—**

1. é…ç½®æ–‡ä»¶

   ```bash
   python train.py --cfg config/adam_config.yaml
   ```

2. è¿è¡Œè®­ç»ƒåï¼Œå¯è§†åŒ–æŸå¤±ï¼š

   ```bash
   python scripts/plot_loss.py
   ```

3. ç»“æœåˆ†æï¼š

   ```bash
   python scripts/analyze.py
   ```

---

## âœ… **ç»“è®º**

è¿™ä¸ª `TODO.md` ç»“æ„æ¸…æ™°ï¼Œä»»åŠ¡æ˜ç¡®ï¼Œå¯ä»¥ç”¨æ¥å¼•å¯¼ **Codex** æ’°å†™ä»£ç ã€‚æ¯ä¸ªå­ä»»åŠ¡å¯ä»¥å•ç‹¬è¿›è¡Œå®ç°ï¼Œé€æ­¥æ„å»ºå®Œæ•´çš„å®éªŒæµç¨‹ã€‚å¦‚æœæœ‰ä»»ä½•è¿›ä¸€æ­¥éœ€æ±‚ï¼Œæ¬¢è¿éšæ—¶è°ƒæ•´æˆ–è¡¥å……ï¼
